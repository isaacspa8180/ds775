---
title: "Week 9 Homework"
author: "Paul Isaacson"
date: "7/18/2017"
output: word_document
---

```{r setup, include=FALSE}
require(gramEvol)
require(GA)
knitr::opts_chunk$set(echo = TRUE)
```

We'll define several functions for you and then you'll use the optimization tools introduced in the presentation to try to find (approximately) optimal solutions to the problems detailed below.   You should include your solutions right in this document and "knit" it into a Word document (just like you did for DS705 assignments).  When you're done, submit both the Word document and this .rmd file to the D2L dropbox.

## Problem 1 - Redistricting with a Genetic Algorithm

Solve problem 13.10-6. Install the 'gramEvol' package to get access to a genetic algorithm that uses integer encoding called GeneticAlg.int().  Use that algorithm to solve this problem.  You'll have to read the documentation to figure out how to use the algorithm.

```{r echo=FALSE, eval = TRUE}

# don't modify this block.

# the distAssign and demrepFit functions go along with problem 13.10-6 from the textbook.
# demrepFit is the function to optimize 

cities = matrix(c(152,81,75,34,62,38,48,74,98,66,83,86,72,28,112,45,93,72,
                  62,59,83,52,87,87,69,49,62,72,75,82,83,53,98,82,68,98),18,2);

distAssign <- function(x){
  # x is an input of 18 integers 1..10 that assign city 1..18 to districts 1..10
  # distAssign is a dataframe with the number of Democrats, Republicans, Total, and Winner
  # in each of the 10 districts
  sumdem = numeric(10);
  sumrep = numeric(10);
  sumtot = numeric(10);
  for (i in 1:10){
    sumdem[i] = sum( cities[x==i,1] );
    sumrep[i] = sum( cities[x==i,2] );
    sumtot[i] = sumdem[i] + sumrep[i];
  }
  distAssign <- data.frame( Dem = sumdem, Rep = sumrep, Tot = sumtot, Win = sumrep>sumdem );
}

demrepFit <- function(x){
  # x is an input of 18 integers 1..10 that assign city 1..18 to districts 1..10
  # demrepfit is the number of districts where Republicans have a majority
  # subtract a penalty proportional to amount by which constraints are violated
  # 
  df <- distAssign(x);
  numRepDist = sum(df$Win);
  sumtot = df$Tot;
  
  # total number of voters is between 150 mil and 350 mil in each district
  # to enforce this constraint we subtract a penalty term equal to the total amount this
  # constraint is violated
  demrepFit = numRepDist - ( sum( 150-sumtot[sumtot<150] )  + sum( sumtot[sumtot>350]-350 ) );
  
  # if the algorithm you use minimizes the fitness instead of maximizing, then
  # uncomment the next line, if your routine maximizes then the next line should be 
  # commented out
  #demrepFit = -demrepFit; 
}

# Notice the constraints aren't explicitly enforced, but instead a penalty term is included in the 
# fitness function to encourage the genetic algorithm to seek potential solutions that satisfy 
# the constraints.
```

In the block below add your code to use the genetic algorithm.   Either experiment with different random number seeds or use a for loop to conduct the optimization many times to find the best solution you can.  

```{r}
result = GeneticAlg.int(genomeLen = 18, codonMin = 1, codonMax = 10, evalFunc = demrepFit, allowrepeat = TRUE, iterations = 1000)
(distAssign(result$best$genome))
```

Make sure you print out your best solution.  How many districts do Republicans win with your solution?  (I don't think Republicans can win all 10 in this example, but they can get close.)

Republicans won 8 districts with my solution.

## Problem 2 - TSP with a Genetic Algorithm

Use the ga() function with permutation encoding from the 'GA' package to approximate a solution to this 48 city TSP problem.  Try different random number seeds and report the best result you can find.  Copy the code from saTSP.R to make a graph of the tour.  Your fitness function is tspFitness().

```{r echo = FALSE}
# this is supposedly the 48 captial cities in the continental United States, 
# but I think things are a little off and I don't know the units.  
# The data is available here
# http://people.sc.fsu.edu/~jburkardt/datasets/tsp/tsp.html

# load the data
D <- as.matrix(read.table("att48_d.txt"))
coord <- as.matrix(read.table("att48_xy.txt"))
# this is supposedly the best possible tour
tour_best <- as.vector(as.matrix(read.table("att48_s.txt")))
tour_best <- tour_best[1:48]
x <- coord[,1];
y <- coord[,2];
n <- length(x);
numcities <- n;

# given a tour, calculate the total distance
tourLength <- function(tour, distMatrix) {
  tour <- c(tour, tour[1])
  route <- embed(tour, 2)[, 2:1]
  sum(distMatrix[route])
}
# inverse of thetotal distance is the fitness (because the GA maximizes)
tspFitness <- function(tour, ...) 1/tourLength(tour, D,...)
#(tspFitness(tour_best,D))
result <- ga(type = 'permutation', fitness = tspFitness, min = 1, max = 48, seed = 100, monitor = FALSE)
summary(result)
result2 <- ga(type = 'permutation', fitness = tspFitness, min = 1, max = 48, seed = 9, monitor = FALSE)
summary(result2)
result3 <- ga(type = 'permutation', fitness = tspFitness, min = 1, max = 48, seed = 25, monitor = FALSE)
summary(result3)
result4 <- ga(type = 'permutation', fitness = tspFitness, min = 1, max = 48, seed = 999, monitor = FALSE)
summary(result4)

loc <- -cmdscale(D, add = TRUE)$points
x <- loc[,1]; y <- loc[,2]
s <- seq_len(nrow(D))

tour <- result@solution
totDist = tourLength(tour,D);
str = c("Tour after GA converged with total distance = ",as.character(totDist));
plot(x, y, type = "n", asp = 1, xlab = "", ylab = "", main = str);
points(x, y, pch = 16, cex = 1.5, col = "grey")
abline(h = pretty(range(x), 10), v = pretty(range(y), 10), col = "lightgrey")
tour <- c(tour, tour[1])
n <- length(tour)
arrows(x[tour[-n]], y[tour[-n]], 
x[tour[-1]], y[tour[-1]], 
length = 0.15, angle = 45, 
col = "steelblue", lwd = 2)
```

## Problem 3 - TSP with Simulated Annealing

Modify the code in saTSP.R and include it below to approximate an optimal tour for the 48 city TSP problem in Problem 2.  Include a graph of the best tour you are able to find.

```{r}
distance <- function(sq) {  # Target function
  sq2 <- embed(sq, 2)
  sum(D[cbind(sq2[,2], sq2[,1])])
}


genseq <- function(sq) {  # Generate new candidate sequence
  idx <- seq(2, NROW(D)-1)
  changepoints <- sample(idx, size = 2, replace = FALSE)
  tmp <- sq[changepoints[1]]
  sq[changepoints[1]] <- sq[changepoints[2]]
  sq[changepoints[2]] <- tmp
  sq
}

sq <- c(1:nrow(D), 1)  # Initial sequence: alphabetic

set.seed(123)
res <- optim(sq, distance, genseq, method = "SANN",
             control = list(maxit = 30000, temp = 2000, trace = TRUE,
                            REPORT = 500))
res

tspres <- loc[res$par,]
plot(x, y, type = "n", asp = 1, xlab = "", ylab = "",
     main = "optim() 'solving' traveling salesman problem", axes = FALSE)
arrows(tspres[s,1], tspres[s,2], tspres[s+1,1], tspres[s+1,2],
       angle = 10, col = "red")
text(x, y, cex = 0.8)
```

How do the results compare to those achieved using a genetic algorithm?  Is one algorithm significantly more efficient than the other?  Compare the total tour distances produced by the two algorithms, does one algorithm consistently produce better results?  

## Problem 4 - Comparing Algorithms for a 30 dimensional Rastrigin function

The 30 dimensional Rastrigin function is considered very difficult to optimize and is a test case for many optimization algorithms.  We know that the global minimum value of 0 occurs at the origin.  For this problem you should compare the performance of Naive Multistart, the Genetic Algorithm plus local search, and the Simulated Annealing algorithm GenSA() from the 'GenSA' package. If you can get it to work, then also try the mlsl() function in the 'nloptr' package as it should work considerably better than Naive Multistart.  

This is a somewhat open problem, but at the very least you should try each algorithm multiple times (possibly in for loop) and report on which algorithms are most efficient (fewest function calls) and which are most reliable (able to consistently identify the global minimum). Experiment with the algorithm parameters (population size, number of iterations of local search, etc.) You'll likely have to increase population sizes and the maximum number of iterations to successfully solve the 30 dimensional problem.  Look at the source code in the presentation .Rmd file included in the download packet for guidance in setting up your algorithms.

```{r echo = FALSE}
Rastrigin <- function(x) {
            (sum(x^2 - 10 * cos(2 * pi  * x)) + 10 * length(x))
}
```

```{r}
# your code goes in this block
dimension = 30;
lower = rep(-5.12,dimension); upper = rep(5.12,dimension); 
x0 = runif(dimension,-5.12,5.12)

bestmin <- 100000;
for (j in 1:10){
  x0 <- as.vector(runif(dimension,min=-5.12,max=5.12));
  result <- optim(x0, Rastrigin, method="L-BFGS-B", lower=lower, upper=upper)
  if (result$value<bestmin){ bestmin = result$value; bestx = result$par}
}
bestmin
bestx

bestmin <- 100000;
for (j in 1:10){
  x0 <- as.vector(runif(dimension,min=-5.12,max=5.12));
  result <- optim(x0, Rastrigin, method="L-BFGS-B", lower=lower, upper=upper)
  if (result$value<bestmin){ bestmin = result$value; bestx = result$par}
}
bestmin
## [1] 174.117
bestx

result = ga(type="real-valued",fitness=Rastrigin,min=lower,max=upper,maxiter=500, monitor=FALSE, seed=100)
result@fitnessValue

result2 = ga(type="real-valued",fitness=Rastrigin,min=lower,max=upper,maxiter=500, monitor=FALSE, seed=99)
result2@fitnessValue

outGenSA <- GenSA(x0, Rastrigin, lower, upper)
outGenSA$value
```

Discuss your algorithm comparison here:
The simulated annealing produced the best result.  
It appears that the optim() function produces similar results
